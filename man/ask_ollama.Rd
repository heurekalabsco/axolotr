% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fun.R
\name{ask_ollama}
\alias{ask_ollama}
\title{Process a Prompt using Ollama local server}
\usage{
ask_ollama(prompt, system = NULL, model = "llama3", ...)
}
\arguments{
\item{prompt}{A character string containing the user's message to the Ollama model.}

\item{system}{An optional character string to provide a system prompt to the model. Default is NULL.}

\item{model}{A character string containing the Ollama model to use. Must be specific and contain the prefix "local_" ("local_llama3", "local_llama3.1").}
}
\value{
A character string containing the Ollama model's response, or NULL if an error occurs.
}
\description{
This function uses the Ollama local server to communicate with a specified Ollama model.
}
